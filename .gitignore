config.py
.venv
__pycache__
llama-2-7b-chat.Q5_K_M.gguf